{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Getting familiar with TensorFlow\n",
    "\n",
    "*TensorFlow* is one of the most popular deep learning framework developed by Google. If you are new to TensorFlow, please read and play with the sample in [Getting started with TensorFlow](https://www.tensorflow.org/get_started/get_started) to get started.\n",
    "\n",
    "* <b>Learning Objective:</b> In Problem 1, you implemented a fully connected network from scratch on your own. Very tedious to do it all by yourself, right? Well, we actually feel the same thing, that's why we are using tools instead of doing everything from scratch. For this part of the assignment, we will familiarize you with a widely-used deep learning framework developed by Google, TensorFlow and walk you through convolutional neural networks and show how to train them.\n",
    "* <b>Provided Codes:</b> We provide the Template class for a simple CNN model as BaseModel, predefined skeletons for conv2d() and max_pool(), as well as the dataset preprocessing parts.\n",
    "* <b>TODOs:</b> You are asked to implement the BaseModel following the detailed instructions and design your own model in YourModel to achieve a reasonably good performance for classification task on CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version 1.13.0-rc2\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "# Add whatever you want\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from lib.datasets import CIFAR10_tf\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print(\"TensorFlow Version {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test matplotlib\n",
    "x = np.linspace(-3, 3, 100)\n",
    "\n",
    "plt.plot(x, np.maximum(0, x), label='relu')\n",
    "plt.plot(x, 1/(1 + np.exp(-x)), label='sigmoid')\n",
    "plt.plot(x, (1 - np.exp(-2 * x))/(1 + np.exp(-2 * x)), label='tanh')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.title(\"Activation functions\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.13.0-rc2\n",
      "2.000000 * 3.000000 = 6.000000\n"
     ]
    }
   ],
   "source": [
    "# Test tensorflow\n",
    "print('TensorFlow version: ' + tf.__version__)\n",
    "a = tf.constant(2.0)\n",
    "b = tf.constant(3.0)\n",
    "c = a * b\n",
    "\n",
    "sess = tf.Session()\n",
    "result = sess.run([a, b, c])\n",
    "print('%f * %f = %f' % (result[0], result[1], result[2]))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets\n",
    "Download [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz) and load the dataset. In this assignment, we will use the standard 50,000 images for training and 10,000 images for test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "num_training = 49000\n",
    "num_validation = 50000 - num_training\n",
    "num_test = 10000\n",
    "\n",
    "data = CIFAR10_tf(num_training=num_training,\n",
    "                  num_validation=num_validation,\n",
    "                  num_test=num_test)\n",
    "\n",
    "# Load cifar-10 data\n",
    "X_train, Y_train = data['data_train'], data['labels_train']\n",
    "X_val, Y_val = data['data_val'], data['labels_val']\n",
    "X_test, Y_test = data['data_test'], data['labels_test']\n",
    "\n",
    "# Check the shape of the dataset\n",
    "assert X_train.shape == (num_training, 32, 32, 3)\n",
    "assert Y_train.shape == (num_training, )\n",
    "assert X_val.shape == (num_validation, 32, 32, 3)\n",
    "assert Y_val.shape == (num_validation, )\n",
    "assert X_test.shape == (num_test, 32, 32, 3)\n",
    "assert Y_test.shape == (10000, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2-1\n",
    "\n",
    "Using the code provided, implement a neural network architecture with an optimization routine according to the specification provided below.\n",
    "\n",
    "**Model:**\n",
    "- Input image with the size 32x32x3\n",
    "- 7x7 convolutional layer with 32 filters, stride of 1, and padding 'SAME'\n",
    "- ReLU activation layer\n",
    "- 3x3 max pooling layer with a stride of 2\n",
    "- 5x5 convolutional layer with 64 filters, stride of 1, and padding 'SAME'\n",
    "- ReLU activation layer\n",
    "- 3x3 max pooling layer with a stride of 2\n",
    "- Flatten layer (8x8x64 -> 4096)\n",
    "- Fully-connected layer with 384 output units (4096 -> 384)\n",
    "- ReLU activation layer\n",
    "- Fully-connected layer with 10 output units (384 -> 10)\n",
    "- Output logits (10)\n",
    "\n",
    "**Optimizer:**\n",
    "- Adam optimizer\n",
    "\n",
    "**Learning rate:**\n",
    "- Set start learning rate as 5e-4 and apply exponential decay every 500 steps with a base of 0.96\n",
    "- Use 'tf.train.exponential_decay' and 'tf.train.AdamOptimizer'\n",
    "\n",
    "**Loss:**\n",
    "- Softmax cross entropy loss\n",
    "- Use 'tf.nn.softmax_cross_entropy_with_logits'\n",
    "\n",
    "\n",
    "Your model **should** achieve about 60% accuracy on validation set in 5 epochs using provided evaluation code.\n",
    "\n",
    "You can modify the template code as you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define your layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define max pooling and conv layers\n",
    "\n",
    "def conv2d(input, kernel_size, stride, num_filter):\n",
    "    stride_shape = [1, stride, stride, 1]\n",
    "    filter_shape = [kernel_size, kernel_size, input.get_shape()[3], num_filter]\n",
    "\n",
    "    W = tf.get_variable('w', filter_shape, tf.float32, tf.random_normal_initializer(0.0, 0.02))\n",
    "    b = tf.get_variable('b', [1, 1, 1, num_filter], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.nn.conv2d(input, W, stride_shape, padding='SAME') + b\n",
    "\n",
    "def max_pool(input, kernel_size, stride):\n",
    "    ksize = [1, kernel_size, kernel_size, 1]\n",
    "    strides = [1, stride, stride, 1]\n",
    "    return tf.nn.max_pool(input, ksize=ksize, strides=strides, padding='SAME')\n",
    "\n",
    "#############################################################################\n",
    "# TODO: Complete the following functions                                    #\n",
    "#############################################################################\n",
    "def flatten(input):\n",
    "    \"\"\"\n",
    "        - input: input tensors\n",
    "    \"\"\"\n",
    "    return tf.layers.flatten(input)\n",
    "\n",
    "def fc(input, num_output):\n",
    "    \"\"\"\n",
    "        - input: input tensors\n",
    "        - num_output: int, the output dimension\n",
    "    \"\"\"\n",
    "    return tf.layers.dense(input, num_output)\n",
    "\n",
    "def norm(input, is_training):\n",
    "    \"\"\"\n",
    "        - input: input tensors\n",
    "        - is_training: boolean, if during training or not\n",
    "    \"\"\"\n",
    "    return tf.layers.batch_normalization(input, training = is_training)\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample convolutional neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(object):\n",
    "    def __init__(self):\n",
    "        self.num_epoch = 5\n",
    "        self.batch_size = 128\n",
    "        self.log_step = 50\n",
    "        self._build_model()\n",
    "\n",
    "    def _model(self):\n",
    "        print('-' * 5 + '  Sample model  ' + '-' * 5)\n",
    "\n",
    "        print('intput layer: ' + str(self.X.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv1'):\n",
    "            self.conv1 = conv2d(self.X, 7, 1, 32)\n",
    "            self.relu1 = tf.nn.relu(self.conv1)\n",
    "            self.pool1 = max_pool(self.relu1, 3, 2)            \n",
    "            print('conv1 layer: ' + str(self.pool1.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv2'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.conv2 = conv2d(self.pool1, 5, 1, 64)\n",
    "            self.relu2 = tf.nn.relu(self.conv2)\n",
    "            self.pool2 = max_pool(self.relu2, 3, 2)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('conv2 layer: ' + str(self.pool2.get_shape()))\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: Flatten the output tensor from conv2 layer                          #\n",
    "        #############################################################################\n",
    "        self.flat = flatten(self.pool2)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################      \n",
    "        print('flat layer: ' + str(self.flat.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('fc3'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc3 = fc(self.flat, 384)\n",
    "            self.relu3 = tf.nn.relu(self.fc3)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc3 layer: ' + str(self.relu3.get_shape()))\n",
    "            \n",
    "        with tf.variable_scope('fc4'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc4 = fc(self.relu3, 10)\n",
    "            self.relu4 = tf.nn.relu(self.fc4)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc4 layer: ' + str(self.fc4.get_shape()))\n",
    "            \n",
    "        # Return the last layer\n",
    "        return self.fc4\n",
    "\n",
    "    def _input_ops(self):\n",
    "        # Placeholders\n",
    "        self.X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        self.Y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: You can add any placeholders                                        #\n",
    "        #############################################################################\n",
    "        \n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        # Adam optimizer 'self.train_op' that minimizes 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "        starter_learning_rate = 0.0005\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step=global_step , decay_steps=500, decay_rate= 0.96)\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate).minimize(self.loss_op, global_step=global_step)    \n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "        \n",
    "    def _loss(self, labels, logits):\n",
    "        # Softmax cross entropy loss 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "        self.loss_op = tf.reduce_mean(loss)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Define input variables\n",
    "        self._input_ops()\n",
    "\n",
    "        # Convert Y to one-hot vector\n",
    "        labels = tf.one_hot(self.Y, 10)\n",
    "\n",
    "        # Build a model and get logits\n",
    "        logits = self._model()\n",
    "\n",
    "        # Compute loss\n",
    "        self._loss(labels, logits)\n",
    "        \n",
    "        # Build optimizer\n",
    "        self._build_optimizer()\n",
    "\n",
    "        # Compute accuracy\n",
    "        predict = tf.argmax(logits, 1)\n",
    "        correct = tf.equal(predict, self.Y)\n",
    "        self.accuracy_op = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "    def train(self, sess, X_train, Y_train, X_val, Y_val):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        print('-' * 5 + '  Start training  ' + '-' * 5)\n",
    "        for epoch in range(self.num_epoch):\n",
    "            print('train for epoch %d' % epoch)\n",
    "            for i in range(num_training // self.batch_size):\n",
    "                X_ = X_train[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "                Y_ = Y_train[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "\n",
    "                #############################################################################\n",
    "                # TODO: You can change feed data as you want                                #\n",
    "                #############################################################################\n",
    "                feed_dict = {self.X : X_, self.Y : Y_}\n",
    "                #############################################################################\n",
    "                #                             END OF YOUR CODE                              #\n",
    "                #############################################################################\n",
    "                fetches = [self.train_op, self.loss_op, self.accuracy_op]\n",
    "\n",
    "                _, loss, accuracy = sess.run(fetches, feed_dict=feed_dict)\n",
    "                losses.append(loss)\n",
    "                accuracies.append(accuracy)\n",
    "\n",
    "                if step % self.log_step == 0:\n",
    "                    print('iteration (%d): loss = %.3f, accuracy = %.3f' %\n",
    "                        (step, loss, accuracy))\n",
    "                step += 1\n",
    "\n",
    "            # Print validation results\n",
    "            print('validation for epoch %d' % epoch)\n",
    "            val_accuracy = self.evaluate(sess, X_val, Y_val)\n",
    "            print('-  epoch %d: validation accuracy = %.3f' % (epoch, val_accuracy))\n",
    "            \n",
    "        #############################################################################\n",
    "        # TODO: Plot training curve                                                 #\n",
    "        #############################################################################\n",
    "        # Graph 1. X: epoch, Y: training loss\n",
    "        plt.title('Training loss')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.plot(range(len(losses)), losses)\n",
    "        plt.show()\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def evaluate(self, sess, X_eval, Y_eval):\n",
    "        eval_accuracy = 0.0\n",
    "        eval_iter = 0\n",
    "        for i in range(X_eval.shape[0] // self.batch_size):\n",
    "            X_ = X_eval[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "            Y_ = Y_eval[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "            \n",
    "            #############################################################################\n",
    "            # TODO: You can change feed data as you want                                #\n",
    "            #############################################################################            \n",
    "            feed_dict = {self.X : X_, self.Y : Y_}\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            accuracy = sess.run(self.accuracy_op, feed_dict=feed_dict)\n",
    "            eval_accuracy += accuracy\n",
    "            eval_iter += 1\n",
    "        return eval_accuracy / eval_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Sample model  -----\n",
      "intput layer: (?, 32, 32, 3)\n",
      "WARNING:tensorflow:From c:\\users\\ahmad\\csci599-assignment1\\env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "conv1 layer: (?, 16, 16, 32)\n",
      "conv2 layer: (?, 8, 8, 64)\n",
      "WARNING:tensorflow:From <ipython-input-5-74894d1ebbc1>:23: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "flat layer: (?, 4096)\n",
      "WARNING:tensorflow:From <ipython-input-5-74894d1ebbc1>:30: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "fc3 layer: (?, 384)\n",
      "fc4 layer: (?, 10)\n",
      "WARNING:tensorflow:From <ipython-input-6-f2e389891022>:96: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "-----  Start training  -----\n",
      "train for epoch 0\n",
      "iteration (0): loss = 14.847, accuracy = 0.047\n",
      "iteration (50): loss = 2.176, accuracy = 0.195\n",
      "iteration (100): loss = 2.034, accuracy = 0.273\n",
      "iteration (150): loss = 1.963, accuracy = 0.227\n",
      "iteration (200): loss = 1.780, accuracy = 0.406\n",
      "iteration (250): loss = 1.716, accuracy = 0.375\n",
      "iteration (300): loss = 1.631, accuracy = 0.414\n",
      "iteration (350): loss = 1.466, accuracy = 0.414\n",
      "validation for epoch 0\n",
      "-  epoch 0: validation accuracy = 0.477\n",
      "train for epoch 1\n",
      "iteration (400): loss = 1.506, accuracy = 0.469\n",
      "iteration (450): loss = 1.457, accuracy = 0.477\n",
      "iteration (500): loss = 1.431, accuracy = 0.508\n",
      "iteration (550): loss = 1.178, accuracy = 0.562\n",
      "iteration (600): loss = 1.418, accuracy = 0.492\n",
      "iteration (650): loss = 1.514, accuracy = 0.414\n",
      "iteration (700): loss = 1.350, accuracy = 0.516\n",
      "iteration (750): loss = 1.074, accuracy = 0.664\n",
      "validation for epoch 1\n",
      "-  epoch 1: validation accuracy = 0.555\n",
      "train for epoch 2\n",
      "iteration (800): loss = 1.197, accuracy = 0.562\n",
      "iteration (850): loss = 1.430, accuracy = 0.477\n",
      "iteration (900): loss = 1.078, accuracy = 0.586\n",
      "iteration (950): loss = 1.107, accuracy = 0.578\n",
      "iteration (1000): loss = 1.126, accuracy = 0.617\n",
      "iteration (1050): loss = 1.115, accuracy = 0.602\n",
      "iteration (1100): loss = 0.992, accuracy = 0.664\n",
      "validation for epoch 2\n",
      "-  epoch 2: validation accuracy = 0.581\n",
      "train for epoch 3\n",
      "iteration (1150): loss = 1.200, accuracy = 0.609\n",
      "iteration (1200): loss = 0.904, accuracy = 0.680\n",
      "iteration (1250): loss = 1.189, accuracy = 0.609\n",
      "iteration (1300): loss = 1.129, accuracy = 0.625\n",
      "iteration (1350): loss = 0.936, accuracy = 0.648\n",
      "iteration (1400): loss = 1.076, accuracy = 0.680\n",
      "iteration (1450): loss = 1.062, accuracy = 0.609\n",
      "iteration (1500): loss = 0.922, accuracy = 0.703\n",
      "validation for epoch 3\n",
      "-  epoch 3: validation accuracy = 0.573\n",
      "train for epoch 4\n",
      "iteration (1550): loss = 0.893, accuracy = 0.664\n",
      "iteration (1600): loss = 0.860, accuracy = 0.727\n",
      "iteration (1650): loss = 1.128, accuracy = 0.641\n",
      "iteration (1700): loss = 0.943, accuracy = 0.641\n",
      "iteration (1750): loss = 0.989, accuracy = 0.680\n",
      "iteration (1800): loss = 1.078, accuracy = 0.625\n",
      "iteration (1850): loss = 0.863, accuracy = 0.711\n",
      "iteration (1900): loss = 0.943, accuracy = 0.648\n",
      "validation for epoch 4\n",
      "-  epoch 4: validation accuracy = 0.624\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEWCAYAAABliCz2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYXHWd7/H3t5d0J51OZ+ssJCEbCSQoWWggBARUlsBFAa8j4AIqd3B80NHRYS7q6KjjvRd1kDs6LoQBwTFsCggqiiwSQCCkE5KQEEIWErJ0ku5s3Z1OL9X9nT/O6bYTej2nqqsP/Xk9Tz9Vdeqcqm+dqv7Ur37nnN8xd0dERN75crJdgIiI9A0FvojIAKHAFxEZIBT4IiIDhAJfRGSAUOCLiAwQCnxJNDPLNbNaMzs+nfNGqOM7ZnZXuh9XJJ3ysl2ADCxmVtvu5hCgAWgOb3/G3Zf05vHcvRkYmu55Rd6JFPjSp9y9LXDNbCvwv9z9yc7mN7M8d0/1RW0i73Tq0pF+Jewaud/M7jWzGuDjZnammb1kZgfNrMLMfmhm+eH8eWbmZjYlvP3L8P4/mFmNmb1oZlN7O294/8Vm9oaZHTKzH5nZX8zskz18HZeb2bqw5qfN7MR2933VzHaZWbWZvW5m54XTF5jZynD6HjP7fhpWqUgbBb70R1cA9wAlwP1ACvgCMBo4C1gEfKaL5T8KfB0YCbwF/Gtv5zWzMcADwI3h874JnN6T4s1sFvBL4PNAKfAk8Fszyzezk8Pa57v7MODi8HkBfgR8P5x+AvDrnjyfSE8p8KU/et7df+vuLe5+xN2Xu/syd0+5+xZgMXBuF8v/2t3L3b0JWALMjTDvpcAqd38kvO9WoKqH9V8FPOruT4fL3gwMA84g+PIqBE4Ou6veDF8TQBMww8xGuXuNuy/r4fOJ9IgCX/qj7e1vmNlJZvZ7M9ttZtXAtwla3Z3Z3e56HV1vqO1s3uPa1+HBKIM7elB767Lb2i3bEi47wd03AF8meA17w66rceGsnwJmAxvM7GUzu6SHzyfSIwp86Y+OHcL1NmAtcELY3fENwDJcQwUwsfWGmRkwoYfL7gImt1s2J3ysnQDu/kt3PwuYCuQC/y+cvsHdrwLGALcAD5pZYfyXIhJQ4EsSFAOHgMNh/3hX/ffp8jtgvpl9wMzyCLYhlPZw2QeAD5rZeeHG5RuBGmCZmc0ys/eaWQFwJPxrBjCzT5jZ6PAXwSGCL76W9L4sGcgU+JIEXwauJQjN2wg25GaUu+8BrgR+AOwDpgOvEBw30N2y6wjq/SlQSbCR+YNhf34B8D2C7QG7gRHAP4eLXgKsD/dO+jfgSndvTOPLkgHOdAIUke6ZWS5BV82H3f25bNcjEoVa+CKdMLNFZlYSdr98nWAPm5ezXJZIZAp8kc6dDWwh6H5ZBFzu7t126Yj0V+rSEREZINTCFxEZIPp08LTRo0f7lClT+vIpRUQSb8WKFVXu3tPdgjvVp4E/ZcoUysvL+/IpRUQSz8y2dT9X99SlIyIyQCjwRUQGCAW+iMgAocAXERkgFPgiIgOEAl9EZIBQ4IuIDBCJCPyDdY38fk1FtssQEUm0RAT+5+99hRvuWcn2/XXZLkVEJLESEfg7DxwBoCGlk/+IiESViMDP+NlLRUQGgEQE/l/zXkM5i4hElYzAtyDyW5T3IiKRJSPws12AiMg7QCICv5VOziUiEl0iAj/s0cHVhy8iElkyAl+dOiIisSUi8FupS0dEJLpuA9/MCs3sZTNbbWbrzOxb4fSpZrbMzDaa2f1mNihTRZoa+CIisfWkhd8AvM/d5wBzgUVmtgD4LnCru88ADgDXZa7MgFr4IiLRdRv4HqgNb+aHfw68D/h1OP1u4PKMVNhOU7OGVhARiapHffhmlmtmq4C9wBPAZuCgu6fCWXYAEzpZ9nozKzez8srKykhFto6l838eWx9peRER6WHgu3uzu88FJgKnA7M6mq2TZRe7e5m7l5WWlkYqsqYh+F555a0DkZYXEZFe7qXj7geBZ4AFwHAzywvvmgjsSm9pIiKSTj3ZS6fUzIaH1wcD5wPrgT8DHw5nuxZ4JFNFiohIfHndz8J44G4zyyX4gnjA3X9nZq8B95nZd4BXgDsyWKeIiMTUbeC7+xpgXgfTtxD05/cZHXErIhJdoo60FRGR6BT4IiIDRLICXz06IiKRJSvwRUQkMgW+iMgAocAXERkgEhX46sIXEYkuUYEvIiLRJSrwdSIUEZHoEhX4OgGKiEh0iQp8ERGJLlGBry4dEZHoEhX46tIREYkuUYGvFr6ISHSJCnwREYlOgS8iMkAkKvB1AhQRkegSFfgiIhKdAl9EZIBIRODPP344AGdOH5XlSkREkisRgd8a9PMmDc9yJSIiyZWIwNfGWhGR+LoNfDObZGZ/NrP1ZrbOzL4QTv+mme00s1Xh3yWZL1dERKLK68E8KeDL7r7SzIqBFWb2RHjfre7+b5krT0RE0qXbwHf3CqAivF5jZuuBCZkurMNasvGkIiLvEL3qwzezKcA8YFk46XNmtsbM7jSzEZ0sc72ZlZtZeWVlZaQiNYaOiEh8PQ58MxsKPAh80d2rgZ8C04G5BL8AbuloOXdf7O5l7l5WWlqahpJFRCSKHgW+meUThP0Sd38IwN33uHuzu7cAtwOnZ65MERGJqyd76RhwB7De3X/Qbvr4drNdAaxNf3lH03j4IiLR9WQvnbOATwCvmtmqcNpXgavNbC7BttStwGcyUiFoL3wRkTToyV46z9Nx5j6W/nJERCRTEnGkrYiIxJeowHftiS8iElkyAl874ouIxJaMwA9pLx0RkeiSFfjZLkBEJMGSEfhq2ouIxJaMwG+l4BcRiSxRga+4FxGJLhGBr6AXEYkvEYHfSj06IiLRJSvw1dYXEYksEYGvlr2ISHyJCPxWCn4RkegSEfitXTnKexGR6BIR+CIiEl+iAl9dOiIi0SUi8FuDXnvpiIhEl4jAFxGR+JIV+Grgi4hElojA92MuRUSk9xIR+CIiEl8iAr9to6120xERiSwRgd9KeS8iEl23gW9mk8zsz2a23szWmdkXwukjzewJM9sYXo7IfLkiIhJVT1r4KeDL7j4LWADcYGazgZuAp9x9BvBUeDsjNLSCiEh83Qa+u1e4+8rweg2wHpgAXAbcHc52N3B5pooUEZH4etWHb2ZTgHnAMmCsu1dA8KUAjOlkmevNrNzMyisrK2MVqz58EZHoehz4ZjYUeBD4ortX93Q5d1/s7mXuXlZaWhqlxra+HA2tICISXY8C38zyCcJ+ibs/FE7eY2bjw/vHA3szU6KIiKRDT/bSMeAOYL27/6DdXY8C14bXrwUeSX95gbYjbdXAFxGJLK8H85wFfAJ41cxWhdO+CtwMPGBm1wFvAX+TmRJFRCQdug18d38esE7ufn96yxERkUxJxJG2rUMqaGgFEZHoEhH4rRT3IiLRJSrwRUQkukQE/l9Hy8xuHSIiSZaIwG+lA69ERKJLROAr5kVE4ktE4LdSl46ISHTJCvxsFyAikmCJCHy17EVE4ktE4LdS8IuIRJeowFenjohIdIkIfO2OKSISXyICv5W6dEREoktE4OtIWxGR+BIR+CIiEl+iAl99+SIi0SUr8JX3IiKRJSrwRUQkukQFvhr4IiLRJSLwdWpDEZH4EhH4rZT7IiLRJSLwve1SiS8iElW3gW9md5rZXjNb227aN81sp5mtCv8uyWyZIiISV09a+HcBizqYfqu7zw3/HktvWZ1QA19EJLJuA9/dnwX290EtXdQQXmazCBGRhIvTh/85M1sTdvmM6GwmM7vezMrNrLyysjLG04mISBxRA/+nwHRgLlAB3NLZjO6+2N3L3L2stLQ04tO1PVas5UVEBrJIge/ue9y92d1bgNuB09Nb1tFuuvgkSgbnq0tHRCSGSIFvZuPb3bwCWNvZvOlQVJDHiCH5mXwKEZF3vLzuZjCze4HzgNFmtgP4F+A8M5tLsB11K/CZDNbYRj06IiLRdRv47n51B5PvyEAtXTIzdemIiMSQiCNtASzbBYiIJFxiAh+0l46ISBzJCXzTgVciInEkJvDVpSMiEk9iAh9QE19EJIbEBH6wl44SX0QkquQEfrYLEBFJuMQEPujAKxGROBIT+GYKfBGROJIT+OrUERGJJTGBDzqnrYhIHIkJfHXpiIjEk5jAFxGReBIV+Grgi4hEl5jANzN16YiIxJCcwM92ASIiCZeYwA+oiS8iElViAt/UxBcRiSUxgQ/aLVNEJI7EBL7pBCgiIrEkJ/C12VZEJJbEBD7onLYiInEkJvDVpSMiEk+3gW9md5rZXjNb227aSDN7wsw2hpcjMlum9sMXEYmrJy38u4BFx0y7CXjK3WcAT4W3M8rMaG5RG19EJKpuA9/dnwX2HzP5MuDu8PrdwOVprutt8nKMFvXhi4hEFrUPf6y7VwCEl2M6m9HMrjezcjMrr6ysjPh0kJNjpJoV+CIiUWV8o627L3b3MncvKy0tjfw4eTnq0hERiSNq4O8xs/EA4eXe9JXUsdwco1ldOiIikUUN/EeBa8Pr1wKPpKeczqmFLyIST092y7wXeBE40cx2mNl1wM3ABWa2EbggvJ1RuTk56sMXEYkhr7sZ3P3qTu56f5pr6ZJa+CIi8STmSNvcXCPV0pLtMkREEis5ga8Dr0REYklM4OflGCkFvohIZIkJ/Jwco0WBLyISWWICP9e0H76ISByJCfycHKNZ22xFRCJLTODn5ugEKCIicSQm8HPUpSMiEkuyAl8bbUVEIktM4OdqLx0RkVgSFfjq0hERiS4xgZ9jhkZWEBGJLkGBj05xKCISQ2ICX106IiLxJCbwc8xw1774IiJRJSbwc3MMQLtmiohElLzAVwtfRCSSxAR+jgWBr7wXEYkmQYEfXKpLR0QkmsQEvrp0RETiSUzgt3bpaHgFEZFoEhP42ktHRCSevDgLm9lWoAZoBlLuXpaOojqSoy4dEZFYYgV+6L3uXpWGx+lSrvbSERGJJTFdOtpLR0QknriB78CfzGyFmV3f0Qxmdr2ZlZtZeWVlZeQnylEfvohILHED/yx3nw9cDNxgZuccO4O7L3b3MncvKy0tjfxErV06GjFTRCSaWIHv7rvCy73Aw8Dp6SiqI9pLR0QknsiBb2ZFZlbceh24EFibrsKO1dqloxa+iEg0cfbSGQs8bEFXSx5wj7v/MS1VdaB1o60a+CIi0UQOfHffAsxJYy1dau3DV5eOiEg0ydktU334IiKxJCbwB+UFpTY260zmIiJRJCbwC8LAb2hS4IuIRJGYwC/MzwWgPtWc5UpERJIpMYGvFr6ISDyJCfzWFn6DWvgiIpEkLvDrmxT4IiJRJCbw27p0UurSERGJIjGBrxa+iEg8iQl8bbQVEYknMYGfn5tDfq5x1wtbeWFTFTsO1LG3pv5tJzVvbnHe2leXpSpFRPqvdJzisM+8e0IJK986yEf/c1m38w7Oz+XdE0p4eet+BuXm0Njcwuihg6iqbeSUiSXc+cnTeL2ihrNnjO6DykVEss+8D4cbLisr8/Ly8sjLb99fxx3Pv8lvV+9i3+HGNFYGP//UaYwtLmT2ccPS+rgiInGZ2Qp3L4v9OEkK/K5UHDrC06/vZcSQQTyzYS97axp4fmMVqZiDrc2ZNJzV2w9y0cljOX/WWI40NfORskkU5ufS1NzC4+t2M2NMMSeMGcrNf1jP6u2HuHHRiZw2ZWSHj7d25yHqm5op6+R+EZFjKfAjeGFzFQ+t3MlVp03ilInD+c0rO/mnB9dEeqyRRYPY38WvjO99+BTuX76dFdsOcP6sMZQMHsSOA3Use3M/AD/7+HwqaxsZVpjHe08aw4ptB/jtql2MKylk58Ej/OOFJzJp5BCamlvIyzHC8w4AUNuQYmhBHs0tzpPr93Dh7LEAR83TV97YU8OookGMGlrQ588tMlAo8NNs095aHl+3m+8/viHbpbQ5bcoIlm89AMCwwjyq61Nt9/3fK97ND5/ayO7qeiaOGMyOA0eOWnbh9FFU1jSwcPooHl29i3Elg/n6/5hFQX4utQ0pzp1Zyt7qeoYNzgeCvaCWvlHJ1qrDjC4uYMqoIsYUF1BaXPC2L5LmFmfZln2cOX0UU7/yGADrvnURRQV5rNh2gByDecePeNvraWnxtmGuW1XXN5FrxuHGFGOKC3lhcxXDCvN514QSWj+b2fgiE+lPFPgZVNeYYl9tI5sra5kwfDAPrtxJizufXDiFZzZUcvtzW3iz6vDblsvNsXf0eP03XnQiSzdU8vLW/R3ef9HJY3l83R4ALj1lPNecOYWP3Pbi2+b74vkzKC7MZ97xw/nQT15omz5tdBFbwvX6yYVTuOuFrQA8csNZ/P8n3+A/PjqfpuYWXn5zPwtPGE1tfYqCvBz+4YFVlA4t4Jozp/C7Nbv42BmTeXFLFYX5uSycPpoWd16rqGbyyCFMKx3aYe2Ln93MeSeO4fiRQ3hjTw2nTBzedt+ug0dYvf0gC6aNomRwPnO+/Sdq6lM8+NmFnDr57V9sEGxvKhmSz7DC/A7vGzY4n5Lwy/bR1buYMWYos8Zr+5F0TIHfD2zfX0dpcQHPb6zi/LBb5eFXdjD/+BFcedtL7K6u56aLT+LFzftY+kYlZZNHUNfYzOlTR7aFWXtnThvFi1v2AXTYapf0GFqQR21Dig/MOY5n36jk0JGmDuczg2P/PfJy7KjtQp9YMJlUi3Pvy28B8OOPzueGe1a23X/d2VOpqW/i0lOO49WdhxhfUsiXHljddv81Z07mFy9uA4Juvm376th+oI6GphZ+/2oFL970fn6zaiev7jzEZ8+bzoqtB9q6IScMH8yXLpjJ+opqLps7gRljh/KTZzZz3dlTGVqQx/qKasYOK2TjnhpOHFfc1u1WXd9EY6qFww0pJo0YwpaqWlZtD2pbOH0UZsaBw43sr2tk6qgiWtz5ykOv8qsVO7hs7nF849LZlAzO5+CRJgbl5VCYl0t9qrnty+2FzVVMGVXEccMHt73OX7y4laqaBn749CZ+ed0Z5OTASeOGMbJoEBAcUJlqcQwoKuh458Ga+iaGDAru21fbwNDCvLbbrZ5+fQ/vmlDCmOLCDh+jN440NjN4UG7k5R9csYP3zxrD8CGDYteiwE+4TXtrKczPYeKIIRysa6T6SIrjRw05ap6KQ0fYtq+Ok8YVc9/y7Xxo3gRqG1Lk5+awYXcND6/aSfWRJi46eRwLpo1k18F67lv+Fh+ccxwXzB7Hqu0HAW/rCvrUz5e3Pfa00iIO1TWRavFOAw+CE8+cUDqU1yqqO7y/uCCPmoZUh/fJwHPq5BGs2BZ0Q9796dNZuqGSX5Vv7/QzMmRQLnWNRx89/8JN7+Nff/cas8cPY/CgXCprG7ht6ZYOly/Mz6G+qYWvXTKLP2/YywubgwbTty87mcvmTKDqcANPvLaHg3VNXH36JD5113Led+IYcnON25Zu4YypI6muT/HZ86aTl2P8ZVMVs8YPo6Y+xXf/+Hrb8zx743vZU1NPU6qFooI8Jo8aQovDvS+/xcyxxfztL8q55W/mcNnc42j24FigC259luLCvPDX4JmcOjn6jhoKfOm1puYWnlq/h4tOHndUv/ibVYcZPjifrfsOU1XbyDkzR1Pf2EJODhSHrbaWFmfJsm28a0IJs8YPY9PeWoYMymXq6CJ+t6aCc08sZXB+Lg2pFmrrU9z469U8t7GKn3xsPgumjWJzZS3f+f16ZowZyqQRQ7j9uS3UNqT42BnHs2TZW1x/zjSuXTiFldsO8NT6PSzfGmzsvjts/X7n8nfxz79Z2+HrWjh9FLPGD+O6s6dS39TM+25ZmtH1eGwrX6Q7J4wZypNfOjfy8gp86deamltYs+Ngp60ad4+0MbZ8637mTBpOc4u3ja90rFR4GkwHntlQyf3Lt3P7NafS4pBjcOhIExt211BaXMBrYbdH6dACDjemqK1Pcca0UUCwcfq/XtxKRXU9m/ce5sLZY5laWnTULrfrK6p5fN1uPjDnOLbtO8ySl97izOmjKCrI449rd7P0jUomjhjMuTNLWbLsraPq/PknT2PV9oP8bOnmowYFvGzucbx7Qgm5Oca3fvvaUctMG11ETbjR/fSpIxkxZBCv7jjI/eXb2VPdcNS8H19wPGOLC8nPy+HmP7xOHKdMLGHNjkNHTbti3gT+uHY3RzS+VY8s/sSpXHjyuEjLKvBFEqC+qbnti8ndqWtsZnB+7tv2VkqnrVWHaUi1cOK44qOm1zWmGJyf2/ZFe+BwI+XbDvD063v5lw/MZt2uQ5w6eSQ19U3srWngYF1TW7dKS4tz8EgTI4sGUVPfhAPDCvNpbnGamlsozM/lwOFG/v6+V3huYxW3X1OGAet2VXO4McWXLpjJzoNHGFU0iKraBvJycli94yBfuG8VcyaW8J4ZpYwZVsAFs8fyL4+sY+H0UXwz/LKbM7GEyaOKmDl2KGedMPqoPcBaWpybHlrDqZNH8J4ZpRQX5rGnuh4wzv/BUhadPI7L503g4Vd2cLgheC+eXB/sWHD+rDE8uX4vwwrzmDq6iNXtvtC+fulsflW+ndd313DrlXN4bmOwS/fKr1/Aj57eyM//spXxJYVUHKrv9v2YNrqIc2aW8uULZ7b9Yu4tBb6IvKO1jozb2S+5qOoaU9Q2pLrdsHvgcCMVh+q7PPr+YF0jq3cc4tyZpW3T1u06xAub9vG350zjwOFGhg/Jj71rcb8IfDNbBPw7kAv8p7vf3NX8CnwRkd5LV+BHHi3TzHKBHwMXA7OBq81sdtyCREQkM+IMj3w6sMndt7h7I3AfcFl6yhIRkXSLE/gTgO3tbu8Ipx3FzK43s3IzK6+srIzxdCIiEkecwO9oK8TbNgi4+2J3L3P3stLS0g4WERGRvhAn8HcAk9rdngjsileOiIhkSpzAXw7MMLOpZjYIuAp4ND1liYhIukU+xaG7p8zsc8DjBLtl3unu69JWmYiIpFWsc9q6+2PAY2mqRUREMqhPj7Q1s0pgW8TFRwNVaSwn3VRfPKovuv5cG6i+uEYDRe4ee6+XPg38OMysPB1HmmWK6otH9UXXn2sD1RdXOuuLs9FWREQSRIEvIjJAJCnwF2e7gG6ovnhUX3T9uTZQfXGlrb7E9OGLiEg8SWrhi4hIDAp8EZEBIhGBb2aLzGyDmW0ys5uy8PyTzOzPZrbezNaZ2RfC6d80s51mtir8u6TdMl8J691gZhf1QY1bzezVsI7ycNpIM3vCzDaGlyPC6WZmPwzrW2Nm8zNc24nt1tEqM6s2sy9mc/2Z2Z1mttfM1rab1uv1ZWbXhvNvNLNrM1zf983s9bCGh81seDh9ipkdabcef9ZumVPDz8Wm8DWk5dyKndTX6/czU//bndR3f7vatprZqnB6n66/LvIk858/d+/XfwTDNmwGpgGDgNXA7D6uYTwwP7xeDLxBcNKXbwL/2MH8s8M6C4CpYf25Ga5xKzD6mGnfA24Kr98EfDe8fgnwB4IRTxcAy/r4/dwNTM7m+gPOAeYDa6OuL2AksCW8HBFeH5HB+i4E8sLr321X35T28x3zOC8DZ4a1/wG4OIP19er9zOT/dkf1HXP/LcA3srH+usiTjH/+ktDCz/qJVty9wt1XhtdrgPV0MPZ/O5cB97l7g7u/CWwieB197TLg7vD63cDl7ab/wgMvAcPNbHwf1fR+YLO7d3XEdcbXn7s/C+zv4Hl7s74uAp5w9/3ufgB4AliUqfrc/U/ungpvvkQwQm2nwhqHufuLHiTEL9q9prTX14XO3s+M/W93VV/YSv8IcG9Xj5Gp9ddFnmT885eEwO/RiVb6iplNAeYBy8JJnwt/Zt3Z+hOM7NTswJ/MbIWZXR9OG+vuFRB8yIAxWayv1VUc/Y/WX9Yf9H59ZXM9fpqg1ddqqpm9YmZLzew94bQJYU19WV9v3s9srb/3AHvcfWO7aVlZf8fkScY/f0kI/B6daKUvmNlQ4EHgi+5eDfwUmA7MBSoIfiZCdmo+y93nE5xj+AYzO6eLebOyTi0YRvuDwK/CSf1p/XWls3qytR6/BqSAJeGkCuB4d58HfAm4x8yGZaG+3r6f2Xqfr+boRkdW1l8HedLprJ3U0ev6khD4/eJEK2aWT/DmLHH3hwDcfY+7N7t7C3A7f+126POa3X1XeLkXeDisZU9rV014uTdb9YUuBla6+56w1n6z/kK9XV99Xme4Ye5S4GNhNwNhV8m+8PoKgn7xmWF97bt9MlpfhPczG+svD/gQcH+7uvt8/XWUJ/TB5y8JgZ/1E62EfX53AOvd/Qftprfv974CaN0j4FHgKjMrMLOpwAyCjT+Zqq/IzIpbrxNs3Fsb1tG65f5a4JF29V0Tbv1fABxq/SmZYUe1rPrL+munt+vrceBCMxsRdl9cGE7LCDNbBPxv4IPuXtdueqmZ5YbXpxGsry1hjTVmtiD8DF/T7jVlor7evp/Z+N8+H3jd3du6avp6/XWWJ/TF5y/uFue++CPYSv0GwTfv17Lw/GcT/FRaA6wK/y4B/gt4NZz+KDC+3TJfC+vdQJr2jOiivmkEezisBta1riNgFPAUsDG8HBlON+DHYX2vAmV9sA6HAPuAknbTsrb+CL54KoAmgpbSdVHWF0Ff+qbw71MZrm8TQZ9t62fwZ+G8/zN831cDK4EPtHucMoLg3Qz8B+HR9Rmqr9fvZ6b+tzuqL5x+F/B3x8zbp+uPzvMk458/Da0gIjJAJKFLR0RE0kCBLyIyQCjwRUQGCAW+iMgAocAXERkgFPiSSGZWG15OMbOPpvmxv3rM7RfS+fgi2aLAl6SbAvQq8FsPsunCUYHv7gt7WZNIv6TAl6S7GXiPBeOY/4OZ5VowbvzycBCvzwCY2XkWjEF+D8HBK5jZb8LB5ta1DjhnZjcDg8PHWxJOa/01YeFjr7VgjPQr2z32M2b2awvGq18SHk0p0q/kZbsAkZhuIhiD/VKAMLgPuftpZlYA/MXM/hTOezrwLg+G6AX4tLvvN7PBwHIze9DdbzKzz7n73A6e60MEA4PNAUaHyzwb3jcPOJlgLJO/AGcBz6f/5YpEpxa+vNNcSDDuyCqCIWdHEYyNAvBj8l0SAAABBUlEQVRyu7AH+HszW00wtvykdvN15mzgXg8GCNsDLAVOa/fYOzwYOGwVQVeTSL+iFr680xjweXc/ahApMzsPOHzM7fOBM929zsyeAQp78NidaWh3vRn9b0k/pBa+JF0NwWniWj0OfDYcfhYzmxmOIHqsEuBAGPYnEZw6rlVT6/LHeBa4MtxOUEpwGr2+GMVTJC3UCpGkWwOkwq6Zu4B/J+hOWRluOK2k49PS/RH4OzNbQzCC40vt7lsMrDGzle7+sXbTHyY4v+lqgtEO/8ndd4dfGCL9nkbLFBEZINSlIyIyQCjwRUQGCAW+iMgAocAXERkgFPgiIgOEAl9EZIBQ4IuIDBD/DaIJKV/X9eWUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** test accuracy: 0.607\n",
      "Model saved in lib/tf_models/problem2/csci-599_sample.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Train our sample model\n",
    "with tf.Session() as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = BaseModel()\n",
    "        model.train(sess, X_train, Y_train, X_val, Y_val)\n",
    "        accuracy = model.evaluate(sess, X_test, Y_test)\n",
    "        print('***** test accuracy: %.3f' % accuracy)\n",
    "        saver = tf.train.Saver()\n",
    "        model_path = saver.save(sess, \"lib/tf_models/problem2/csci-599_sample.ckpt\")\n",
    "        print(\"Model saved in %s\" % model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2-2\n",
    "\n",
    "Implement your own model. \n",
    "\n",
    "You can modify the template code as you want and you can use GPU for fast training.  \n",
    "For GPU usage, simply change the following line of the training block:  \n",
    "from `with tf.device('/cpu:0')` to `with tf.device('/GPU:0')`  \n",
    "and you can set your desired device number  \n",
    "\n",
    "These are the techniques that you can try:\n",
    "- Data preprocessing\n",
    "- Data augmentation\n",
    "- Dropout\n",
    "- Batch normalization\n",
    "- More convolutional layers\n",
    "- More training epochs\n",
    "- Learning rate decay\n",
    "- Any other models and techniqes\n",
    "\n",
    "Your model should achieve >= 70% accuracy on the test set of CIFAR-10.\n",
    "\n",
    "If the accuracy of the model reaches to 80%, you will get 5 extra points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YourModel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super(YourModel, self).__init__()\n",
    "        self.num_epoch = 30\n",
    "\n",
    "    def _model(self):\n",
    "        print('-' * 5 + '  Your model  ' + '-' * 5)\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: Implement you own model here                                        #\n",
    "        #############################################################################\n",
    "        print('intput layer: ' + str(self.X.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv1'):\n",
    "            self.conv1 = conv2d(self.X, 7, 1, 32)\n",
    "            self.relu1 = tf.nn.relu(self.conv1)\n",
    "            self.norm1 = tf.nn.lrn(self.relu1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "            self.pool1 = max_pool(self.norm1, 3, 2)            \n",
    "            print('conv1 layer: ' + str(self.pool1.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv2'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.conv2 = conv2d(self.pool1, 5, 1, 64)\n",
    "            self.relu2 = tf.nn.relu(self.conv2)\n",
    "            self.norm2 = tf.nn.lrn(self.relu2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "            self.pool2 = max_pool(self.norm2, 3, 2)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('conv2 layer: ' + str(self.pool2.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('conv3'):\n",
    "            self.conv3 = conv2d(self.pool2, 3, 1, 32)\n",
    "            self.relu3 = tf.nn.relu(self.conv3)\n",
    "            self.norm3 = tf.nn.lrn(self.relu3, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "            self.pool3 = max_pool(self.norm3, 3, 2)            \n",
    "            print('conv3 layer: ' + str(self.pool3.get_shape()))    \n",
    "            \n",
    "        #############################################################################\n",
    "        # TODO: Flatten the output tensor from conv2 layer                          #\n",
    "        #############################################################################\n",
    "        self.flat = flatten(self.pool3)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################      \n",
    "        print('flat layer: ' + str(self.flat.get_shape()))\n",
    "\n",
    "        with tf.variable_scope('fc3'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc3 = fc(self.flat, 384)\n",
    "            self.relu3 = tf.nn.relu(self.fc3)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc3 layer: ' + str(self.relu3.get_shape()))\n",
    "            \n",
    "        with tf.variable_scope('fc4'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc4 = fc(self.relu3, 100)\n",
    "            self.relu4 = tf.nn.relu(self.fc4)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc4 layer: ' + str(self.fc4.get_shape()))\n",
    "        \n",
    "        with tf.variable_scope('fc5'):\n",
    "            #############################################################################\n",
    "            # TODO: Complete the following functions                                    #\n",
    "            #############################################################################\n",
    "            self.fc5 = fc(self.relu4, 10)\n",
    "            self.relu5 = tf.nn.relu(self.fc5)\n",
    "            #############################################################################\n",
    "            #                             END OF YOUR CODE                              #\n",
    "            #############################################################################\n",
    "            print('fc5 layer: ' + str(self.fc5.get_shape()))        \n",
    "            \n",
    "        # Return the last layer\n",
    "        return self.fc5\n",
    "\n",
    "    def _input_ops(self):\n",
    "        # Placeholders\n",
    "        self.X = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "        self.Y = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "        #############################################################################\n",
    "        # TODO: You can add any placeholders                                        #\n",
    "        #############################################################################\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_optimizer(self):\n",
    "        # Adam optimizer 'self.train_op' that minimizes 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "        starter_learning_rate = 0.00005\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step=global_step , decay_steps=1500, decay_rate= 0.96, staircase=True)\n",
    "        self.train_op = tf.train.AdamOptimizer(learning_rate).minimize(self.loss_op, global_step=global_step)    \n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "        \n",
    "    def _loss(self, labels, logits):\n",
    "        # Softmax cross entropy loss 'self.loss_op'\n",
    "        #############################################################################\n",
    "        # TODO: Complete the following functions                                    #\n",
    "        #############################################################################\n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "        self.loss_op = tf.reduce_mean(loss)\n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Define input variables\n",
    "        self._input_ops()\n",
    "\n",
    "        # Convert Y to one-hot vector\n",
    "        labels = tf.one_hot(self.Y, 10)\n",
    "\n",
    "        # Build a model and get logits\n",
    "        logits = self._model()\n",
    "\n",
    "        # Compute loss\n",
    "        self._loss(labels, logits)\n",
    "        \n",
    "        # Build optimizer\n",
    "        self._build_optimizer()\n",
    "\n",
    "        # Compute accuracy\n",
    "        predict = tf.argmax(logits, 1)\n",
    "        correct = tf.equal(predict, self.Y)\n",
    "        self.accuracy_op = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "        \n",
    "    def train(self, sess, X_train, Y_train, X_val, Y_val):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        step = 0\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        print('-' * 5 + '  Start training  ' + '-' * 5)\n",
    "        for epoch in range(self.num_epoch):\n",
    "            print('train for epoch %d' % epoch)\n",
    "            for i in range(num_training // self.batch_size):\n",
    "                X_ = X_train[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "                Y_ = Y_train[i * self.batch_size:(i + 1) * self.batch_size]\n",
    "                feed_dict = {self.X : X_, self.Y : Y_, self.keep_prob: 0.5}\n",
    "                fetches = [self.train_op, self.loss_op, self.accuracy_op]\n",
    "\n",
    "                _, loss, accuracy = sess.run(fetches, feed_dict=feed_dict)\n",
    "                losses.append(loss)\n",
    "                accuracies.append(accuracy)\n",
    "\n",
    "                if step % self.log_step == 0:\n",
    "                    print('iteration (%d): loss = %.3f, accuracy = %.3f' %\n",
    "                        (step, loss, accuracy))\n",
    "                step += 1\n",
    "\n",
    "            # Print validation results\n",
    "            print('validation for epoch %d' % epoch)\n",
    "            val_accuracy = self.evaluate(sess, X_val, Y_val)\n",
    "            print('-  epoch %d: validation accuracy = %.3f' % (epoch, val_accuracy))\n",
    "\n",
    "\n",
    "    def evaluate(self, sess, X_eval, Y_eval):\n",
    "        eval_accuracy = 0.0\n",
    "        eval_iter = 0\n",
    "        for i in range(X_eval.shape[0] // self.batch_size):\n",
    "            X_ = X_eval[i * self.batch_size:(i + 1) * self.batch_size][:]\n",
    "            Y_ = Y_eval[i * self.batch_size:(i + 1) * self.batch_size]         \n",
    "            feed_dict = {self.X : X_, self.Y : Y_, self.keep_prob: 1.0}\n",
    "            accuracy = sess.run(self.accuracy_op, feed_dict=feed_dict)\n",
    "            eval_accuracy += accuracy\n",
    "            eval_iter += 1\n",
    "        return eval_accuracy / eval_iter        \n",
    "        #############################################################################\n",
    "        #                             END OF YOUR CODE                              #\n",
    "        #############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Your model  -----\n",
      "intput layer: (?, 32, 32, 3)\n",
      "conv1 layer: (?, 16, 16, 32)\n",
      "conv2 layer: (?, 8, 8, 64)\n",
      "conv3 layer: (?, 4, 4, 32)\n",
      "flat layer: (?, 512)\n",
      "fc3 layer: (?, 384)\n",
      "fc4 layer: (?, 100)\n",
      "fc5 layer: (?, 10)\n",
      "-----  Start training  -----\n",
      "train for epoch 0\n",
      "iteration (0): loss = 6.735, accuracy = 0.117\n",
      "iteration (50): loss = 2.168, accuracy = 0.211\n",
      "iteration (100): loss = 1.905, accuracy = 0.289\n",
      "iteration (150): loss = 1.943, accuracy = 0.227\n",
      "iteration (200): loss = 1.772, accuracy = 0.367\n",
      "iteration (250): loss = 1.644, accuracy = 0.438\n",
      "iteration (300): loss = 1.553, accuracy = 0.453\n",
      "iteration (350): loss = 1.604, accuracy = 0.438\n",
      "validation for epoch 0\n",
      "-  epoch 0: validation accuracy = 0.469\n",
      "train for epoch 1\n",
      "iteration (400): loss = 1.538, accuracy = 0.445\n",
      "iteration (450): loss = 1.596, accuracy = 0.453\n",
      "iteration (500): loss = 1.495, accuracy = 0.508\n",
      "iteration (550): loss = 1.381, accuracy = 0.516\n",
      "iteration (600): loss = 1.530, accuracy = 0.508\n",
      "iteration (650): loss = 1.540, accuracy = 0.453\n",
      "iteration (700): loss = 1.446, accuracy = 0.500\n",
      "iteration (750): loss = 1.292, accuracy = 0.547\n",
      "validation for epoch 1\n",
      "-  epoch 1: validation accuracy = 0.539\n",
      "train for epoch 2\n",
      "iteration (800): loss = 1.245, accuracy = 0.508\n",
      "iteration (850): loss = 1.515, accuracy = 0.445\n",
      "iteration (900): loss = 1.275, accuracy = 0.492\n",
      "iteration (950): loss = 1.224, accuracy = 0.562\n",
      "iteration (1000): loss = 1.292, accuracy = 0.539\n",
      "iteration (1050): loss = 1.197, accuracy = 0.547\n",
      "iteration (1100): loss = 1.182, accuracy = 0.609\n",
      "validation for epoch 2\n",
      "-  epoch 2: validation accuracy = 0.565\n",
      "train for epoch 3\n",
      "iteration (1150): loss = 1.197, accuracy = 0.633\n",
      "iteration (1200): loss = 1.077, accuracy = 0.617\n",
      "iteration (1250): loss = 1.217, accuracy = 0.555\n",
      "iteration (1300): loss = 1.330, accuracy = 0.547\n",
      "iteration (1350): loss = 1.074, accuracy = 0.625\n",
      "iteration (1400): loss = 1.223, accuracy = 0.562\n",
      "iteration (1450): loss = 1.173, accuracy = 0.555\n",
      "iteration (1500): loss = 0.944, accuracy = 0.656\n",
      "validation for epoch 3\n",
      "-  epoch 3: validation accuracy = 0.594\n",
      "train for epoch 4\n",
      "iteration (1550): loss = 0.892, accuracy = 0.734\n",
      "iteration (1600): loss = 1.061, accuracy = 0.586\n",
      "iteration (1650): loss = 1.136, accuracy = 0.562\n",
      "iteration (1700): loss = 1.078, accuracy = 0.586\n",
      "iteration (1750): loss = 1.130, accuracy = 0.578\n",
      "iteration (1800): loss = 1.071, accuracy = 0.594\n",
      "iteration (1850): loss = 1.133, accuracy = 0.594\n",
      "iteration (1900): loss = 1.035, accuracy = 0.641\n",
      "validation for epoch 4\n",
      "-  epoch 4: validation accuracy = 0.613\n",
      "train for epoch 5\n",
      "iteration (1950): loss = 1.232, accuracy = 0.578\n",
      "iteration (2000): loss = 0.967, accuracy = 0.680\n",
      "iteration (2050): loss = 1.094, accuracy = 0.609\n",
      "iteration (2100): loss = 1.026, accuracy = 0.641\n",
      "iteration (2150): loss = 1.140, accuracy = 0.570\n",
      "iteration (2200): loss = 1.074, accuracy = 0.594\n",
      "iteration (2250): loss = 1.012, accuracy = 0.648\n",
      "validation for epoch 5\n",
      "-  epoch 5: validation accuracy = 0.625\n",
      "train for epoch 6\n",
      "iteration (2300): loss = 0.989, accuracy = 0.688\n",
      "iteration (2350): loss = 0.868, accuracy = 0.695\n",
      "iteration (2400): loss = 1.066, accuracy = 0.625\n",
      "iteration (2450): loss = 1.129, accuracy = 0.570\n",
      "iteration (2500): loss = 1.059, accuracy = 0.648\n",
      "iteration (2550): loss = 1.038, accuracy = 0.555\n",
      "iteration (2600): loss = 0.998, accuracy = 0.641\n",
      "iteration (2650): loss = 0.984, accuracy = 0.641\n",
      "validation for epoch 6\n",
      "-  epoch 6: validation accuracy = 0.633\n",
      "train for epoch 7\n",
      "iteration (2700): loss = 1.145, accuracy = 0.617\n",
      "iteration (2750): loss = 1.010, accuracy = 0.625\n",
      "iteration (2800): loss = 0.969, accuracy = 0.656\n",
      "iteration (2850): loss = 0.913, accuracy = 0.672\n",
      "iteration (2900): loss = 0.925, accuracy = 0.680\n",
      "iteration (2950): loss = 0.824, accuracy = 0.664\n",
      "iteration (3000): loss = 0.801, accuracy = 0.773\n",
      "iteration (3050): loss = 0.999, accuracy = 0.672\n",
      "validation for epoch 7\n",
      "-  epoch 7: validation accuracy = 0.629\n",
      "train for epoch 8\n",
      "iteration (3100): loss = 0.975, accuracy = 0.609\n",
      "iteration (3150): loss = 0.931, accuracy = 0.648\n",
      "iteration (3200): loss = 1.084, accuracy = 0.594\n",
      "iteration (3250): loss = 1.108, accuracy = 0.609\n",
      "iteration (3300): loss = 0.754, accuracy = 0.742\n",
      "iteration (3350): loss = 0.960, accuracy = 0.656\n",
      "iteration (3400): loss = 0.892, accuracy = 0.680\n",
      "validation for epoch 8\n",
      "-  epoch 8: validation accuracy = 0.638\n",
      "train for epoch 9\n",
      "iteration (3450): loss = 0.797, accuracy = 0.750\n",
      "iteration (3500): loss = 0.882, accuracy = 0.688\n",
      "iteration (3550): loss = 0.903, accuracy = 0.711\n",
      "iteration (3600): loss = 0.884, accuracy = 0.719\n",
      "iteration (3650): loss = 0.921, accuracy = 0.703\n",
      "iteration (3700): loss = 0.967, accuracy = 0.656\n",
      "iteration (3750): loss = 0.885, accuracy = 0.695\n",
      "iteration (3800): loss = 0.807, accuracy = 0.695\n",
      "validation for epoch 9\n",
      "-  epoch 9: validation accuracy = 0.651\n",
      "train for epoch 10\n",
      "iteration (3850): loss = 0.883, accuracy = 0.688\n",
      "iteration (3900): loss = 0.738, accuracy = 0.727\n",
      "iteration (3950): loss = 0.829, accuracy = 0.688\n",
      "iteration (4000): loss = 0.833, accuracy = 0.719\n",
      "iteration (4050): loss = 0.758, accuracy = 0.758\n",
      "iteration (4100): loss = 0.768, accuracy = 0.758\n",
      "iteration (4150): loss = 0.695, accuracy = 0.758\n",
      "iteration (4200): loss = 0.910, accuracy = 0.688\n",
      "validation for epoch 10\n",
      "-  epoch 10: validation accuracy = 0.654\n",
      "train for epoch 11\n",
      "iteration (4250): loss = 0.784, accuracy = 0.711\n",
      "iteration (4300): loss = 0.891, accuracy = 0.734\n",
      "iteration (4350): loss = 0.843, accuracy = 0.727\n",
      "iteration (4400): loss = 0.865, accuracy = 0.695\n",
      "iteration (4450): loss = 0.850, accuracy = 0.711\n",
      "iteration (4500): loss = 0.858, accuracy = 0.703\n",
      "iteration (4550): loss = 0.798, accuracy = 0.719\n",
      "validation for epoch 11\n",
      "-  epoch 11: validation accuracy = 0.657\n",
      "train for epoch 12\n",
      "iteration (4600): loss = 0.654, accuracy = 0.742\n",
      "iteration (4650): loss = 0.834, accuracy = 0.680\n",
      "iteration (4700): loss = 0.894, accuracy = 0.719\n",
      "iteration (4750): loss = 0.773, accuracy = 0.758\n",
      "iteration (4800): loss = 0.702, accuracy = 0.766\n",
      "iteration (4850): loss = 0.680, accuracy = 0.727\n",
      "iteration (4900): loss = 0.840, accuracy = 0.727\n",
      "iteration (4950): loss = 0.720, accuracy = 0.742\n",
      "validation for epoch 12\n",
      "-  epoch 12: validation accuracy = 0.673\n",
      "train for epoch 13\n",
      "iteration (5000): loss = 0.683, accuracy = 0.797\n",
      "iteration (5050): loss = 0.844, accuracy = 0.719\n",
      "iteration (5100): loss = 0.662, accuracy = 0.766\n",
      "iteration (5150): loss = 0.828, accuracy = 0.719\n",
      "iteration (5200): loss = 0.689, accuracy = 0.734\n",
      "iteration (5250): loss = 0.722, accuracy = 0.758\n",
      "iteration (5300): loss = 0.687, accuracy = 0.773\n",
      "validation for epoch 13\n",
      "-  epoch 13: validation accuracy = 0.673\n",
      "train for epoch 14\n",
      "iteration (5350): loss = 0.797, accuracy = 0.695\n",
      "iteration (5400): loss = 0.734, accuracy = 0.742\n",
      "iteration (5450): loss = 0.764, accuracy = 0.703\n",
      "iteration (5500): loss = 0.739, accuracy = 0.750\n",
      "iteration (5550): loss = 0.768, accuracy = 0.727\n",
      "iteration (5600): loss = 0.838, accuracy = 0.703\n",
      "iteration (5650): loss = 0.684, accuracy = 0.742\n",
      "iteration (5700): loss = 0.778, accuracy = 0.789\n",
      "validation for epoch 14\n",
      "-  epoch 14: validation accuracy = 0.684\n",
      "train for epoch 15\n",
      "iteration (5750): loss = 0.539, accuracy = 0.781\n",
      "iteration (5800): loss = 0.816, accuracy = 0.703\n",
      "iteration (5850): loss = 0.584, accuracy = 0.781\n",
      "iteration (5900): loss = 0.689, accuracy = 0.758\n",
      "iteration (5950): loss = 0.699, accuracy = 0.773\n",
      "iteration (6000): loss = 0.782, accuracy = 0.727\n",
      "iteration (6050): loss = 0.833, accuracy = 0.664\n",
      "iteration (6100): loss = 0.754, accuracy = 0.734\n",
      "validation for epoch 15\n",
      "-  epoch 15: validation accuracy = 0.690\n",
      "train for epoch 16\n",
      "iteration (6150): loss = 0.830, accuracy = 0.750\n",
      "iteration (6200): loss = 0.664, accuracy = 0.773\n",
      "iteration (6250): loss = 0.895, accuracy = 0.664\n",
      "iteration (6300): loss = 0.611, accuracy = 0.797\n",
      "iteration (6350): loss = 0.774, accuracy = 0.773\n",
      "iteration (6400): loss = 0.923, accuracy = 0.719\n",
      "iteration (6450): loss = 0.708, accuracy = 0.750\n",
      "validation for epoch 16\n",
      "-  epoch 16: validation accuracy = 0.689\n",
      "train for epoch 17\n",
      "iteration (6500): loss = 0.765, accuracy = 0.703\n",
      "iteration (6550): loss = 0.654, accuracy = 0.812\n",
      "iteration (6600): loss = 0.766, accuracy = 0.711\n",
      "iteration (6650): loss = 0.686, accuracy = 0.766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration (6700): loss = 0.623, accuracy = 0.734\n",
      "iteration (6750): loss = 0.818, accuracy = 0.734\n",
      "iteration (6800): loss = 0.610, accuracy = 0.797\n",
      "iteration (6850): loss = 0.671, accuracy = 0.766\n",
      "validation for epoch 17\n",
      "-  epoch 17: validation accuracy = 0.688\n",
      "train for epoch 18\n",
      "iteration (6900): loss = 0.683, accuracy = 0.758\n",
      "iteration (6950): loss = 0.678, accuracy = 0.781\n",
      "iteration (7000): loss = 0.724, accuracy = 0.773\n",
      "iteration (7050): loss = 0.686, accuracy = 0.727\n",
      "iteration (7100): loss = 0.635, accuracy = 0.820\n",
      "iteration (7150): loss = 0.790, accuracy = 0.734\n",
      "iteration (7200): loss = 0.783, accuracy = 0.727\n",
      "iteration (7250): loss = 0.623, accuracy = 0.758\n",
      "validation for epoch 18\n",
      "-  epoch 18: validation accuracy = 0.691\n",
      "train for epoch 19\n",
      "iteration (7300): loss = 0.831, accuracy = 0.742\n",
      "iteration (7350): loss = 0.810, accuracy = 0.742\n",
      "iteration (7400): loss = 0.776, accuracy = 0.695\n",
      "iteration (7450): loss = 0.555, accuracy = 0.789\n",
      "iteration (7500): loss = 0.680, accuracy = 0.750\n",
      "iteration (7550): loss = 0.619, accuracy = 0.797\n",
      "iteration (7600): loss = 0.619, accuracy = 0.805\n",
      "validation for epoch 19\n",
      "-  epoch 19: validation accuracy = 0.695\n",
      "train for epoch 20\n",
      "iteration (7650): loss = 0.680, accuracy = 0.797\n",
      "iteration (7700): loss = 0.671, accuracy = 0.758\n",
      "iteration (7750): loss = 0.654, accuracy = 0.789\n",
      "iteration (7800): loss = 0.542, accuracy = 0.805\n",
      "iteration (7850): loss = 0.655, accuracy = 0.758\n",
      "iteration (7900): loss = 0.693, accuracy = 0.750\n",
      "iteration (7950): loss = 0.905, accuracy = 0.711\n",
      "iteration (8000): loss = 0.578, accuracy = 0.812\n",
      "validation for epoch 20\n",
      "-  epoch 20: validation accuracy = 0.698\n",
      "train for epoch 21\n",
      "iteration (8050): loss = 0.505, accuracy = 0.844\n",
      "iteration (8100): loss = 0.615, accuracy = 0.812\n",
      "iteration (8150): loss = 0.680, accuracy = 0.797\n",
      "iteration (8200): loss = 0.685, accuracy = 0.750\n",
      "iteration (8250): loss = 0.584, accuracy = 0.812\n",
      "iteration (8300): loss = 0.552, accuracy = 0.797\n",
      "iteration (8350): loss = 0.610, accuracy = 0.789\n",
      "iteration (8400): loss = 0.472, accuracy = 0.859\n",
      "validation for epoch 21\n",
      "-  epoch 21: validation accuracy = 0.699\n",
      "train for epoch 22\n",
      "iteration (8450): loss = 0.518, accuracy = 0.805\n",
      "iteration (8500): loss = 0.683, accuracy = 0.742\n",
      "iteration (8550): loss = 0.561, accuracy = 0.797\n",
      "iteration (8600): loss = 0.569, accuracy = 0.797\n",
      "iteration (8650): loss = 0.604, accuracy = 0.812\n",
      "iteration (8700): loss = 0.582, accuracy = 0.766\n",
      "iteration (8750): loss = 0.620, accuracy = 0.742\n",
      "validation for epoch 22\n",
      "-  epoch 22: validation accuracy = 0.702\n",
      "train for epoch 23\n",
      "iteration (8800): loss = 0.426, accuracy = 0.859\n",
      "iteration (8850): loss = 0.554, accuracy = 0.805\n",
      "iteration (8900): loss = 0.634, accuracy = 0.766\n",
      "iteration (8950): loss = 0.597, accuracy = 0.805\n",
      "iteration (9000): loss = 0.614, accuracy = 0.766\n",
      "iteration (9050): loss = 0.828, accuracy = 0.742\n",
      "iteration (9100): loss = 0.536, accuracy = 0.820\n",
      "iteration (9150): loss = 0.566, accuracy = 0.789\n",
      "validation for epoch 23\n",
      "-  epoch 23: validation accuracy = 0.698\n",
      "train for epoch 24\n",
      "iteration (9200): loss = 0.550, accuracy = 0.828\n",
      "iteration (9250): loss = 0.625, accuracy = 0.789\n",
      "iteration (9300): loss = 0.582, accuracy = 0.789\n",
      "iteration (9350): loss = 0.447, accuracy = 0.867\n",
      "iteration (9400): loss = 0.573, accuracy = 0.805\n",
      "iteration (9450): loss = 0.678, accuracy = 0.758\n",
      "iteration (9500): loss = 0.787, accuracy = 0.742\n",
      "validation for epoch 24\n",
      "-  epoch 24: validation accuracy = 0.699\n",
      "train for epoch 25\n",
      "iteration (9550): loss = 0.507, accuracy = 0.844\n",
      "iteration (9600): loss = 0.584, accuracy = 0.797\n",
      "iteration (9650): loss = 0.487, accuracy = 0.844\n",
      "iteration (9700): loss = 0.515, accuracy = 0.852\n",
      "iteration (9750): loss = 0.626, accuracy = 0.805\n",
      "iteration (9800): loss = 0.758, accuracy = 0.742\n",
      "iteration (9850): loss = 0.666, accuracy = 0.758\n",
      "iteration (9900): loss = 0.672, accuracy = 0.734\n",
      "validation for epoch 25\n",
      "-  epoch 25: validation accuracy = 0.704\n",
      "train for epoch 26\n",
      "iteration (9950): loss = 0.461, accuracy = 0.812\n",
      "iteration (10000): loss = 0.591, accuracy = 0.766\n",
      "iteration (10050): loss = 0.577, accuracy = 0.812\n",
      "iteration (10100): loss = 0.566, accuracy = 0.805\n",
      "iteration (10150): loss = 0.565, accuracy = 0.844\n",
      "iteration (10200): loss = 0.683, accuracy = 0.719\n",
      "iteration (10250): loss = 0.490, accuracy = 0.883\n",
      "iteration (10300): loss = 0.462, accuracy = 0.852\n",
      "validation for epoch 26\n",
      "-  epoch 26: validation accuracy = 0.703\n",
      "train for epoch 27\n",
      "iteration (10350): loss = 0.474, accuracy = 0.836\n",
      "iteration (10400): loss = 0.632, accuracy = 0.789\n",
      "iteration (10450): loss = 0.540, accuracy = 0.812\n",
      "iteration (10500): loss = 0.499, accuracy = 0.844\n",
      "iteration (10550): loss = 0.462, accuracy = 0.852\n",
      "iteration (10600): loss = 0.587, accuracy = 0.781\n",
      "iteration (10650): loss = 0.575, accuracy = 0.789\n",
      "validation for epoch 27\n",
      "-  epoch 27: validation accuracy = 0.695\n",
      "train for epoch 28\n",
      "iteration (10700): loss = 0.581, accuracy = 0.797\n",
      "iteration (10750): loss = 0.462, accuracy = 0.867\n",
      "iteration (10800): loss = 0.472, accuracy = 0.852\n",
      "iteration (10850): loss = 0.633, accuracy = 0.781\n",
      "iteration (10900): loss = 0.491, accuracy = 0.859\n",
      "iteration (10950): loss = 0.559, accuracy = 0.805\n",
      "iteration (11000): loss = 0.518, accuracy = 0.781\n",
      "iteration (11050): loss = 0.420, accuracy = 0.852\n",
      "validation for epoch 28\n",
      "-  epoch 28: validation accuracy = 0.693\n",
      "train for epoch 29\n",
      "iteration (11100): loss = 0.384, accuracy = 0.891\n",
      "iteration (11150): loss = 0.550, accuracy = 0.805\n",
      "iteration (11200): loss = 0.566, accuracy = 0.828\n",
      "iteration (11250): loss = 0.552, accuracy = 0.797\n",
      "iteration (11300): loss = 0.571, accuracy = 0.797\n",
      "iteration (11350): loss = 0.506, accuracy = 0.828\n",
      "iteration (11400): loss = 0.502, accuracy = 0.859\n",
      "iteration (11450): loss = 0.488, accuracy = 0.812\n",
      "validation for epoch 29\n",
      "-  epoch 29: validation accuracy = 0.695\n",
      "***** test accuracy: 0.695\n",
      "Model saved in lib/tf_models/problem2/csci-599_mine.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Clear old computation graphs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    with tf.device('/cpu:0'):\n",
    "        model = YourModel()\n",
    "        model.train(sess, X_train, Y_train, X_val, Y_val)\n",
    "        accuracy = model.evaluate(sess, X_test, Y_test)\n",
    "        print('***** test accuracy: %.3f' % accuracy)\n",
    "        # Save your model\n",
    "        saver = tf.train.Saver()\n",
    "        model_path = saver.save(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")\n",
    "        print(\"Model saved in %s\" % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----  Your model  -----\n",
      "intput layer: (?, 32, 32, 3)\n",
      "conv1 layer: (?, 16, 16, 32)\n",
      "conv2 layer: (?, 8, 8, 64)\n",
      "conv3 layer: (?, 4, 4, 32)\n",
      "flat layer: (?, 512)\n",
      "fc3 layer: (?, 384)\n",
      "fc4 layer: (?, 100)\n",
      "fc5 layer: (?, 10)\n",
      "WARNING:tensorflow:From c:\\users\\ahmad\\csci599-assignment1\\env\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from lib/tf_models/problem2/csci-599_mine.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# Load your model\n",
    "model = YourModel()\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"lib/tf_models/problem2/csci-599_mine.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
